---
title: "Assignment5"
author: "Holly Finertie - HF2379"
date: 'Due: 2/25/2020'
output:
  word_document: default
  html_document: default
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(caret)
library(glmnet)
library(modelr)
library(mgcv)

set.seed(100)
```

Goal: You want to predict current alcohol consumption but it is expensive and time-consuming to administer all of the behavioral testing that produces the personality scores. You will conduct a reproducible analysis to build and test classification models using regularized logistic regression and traditional logistic regression.

### Data Import: Cleaning and Training/Testing Data Set

I imported the data, cleaned the variable names, and converted our outcome of interest to a factor variable named 'alc_outcome'. Then I created training and testing data sets with a 70/30 split. 

```{r, import}
alc = read_csv("./data/alcohol_use.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    alc_outcome = case_when(
      alc_consumption == "CurrentUse" ~ 1, 
      alc_consumption == "NotCurrentUse" ~ 0), 
    alc_outcome = as.factor(alc_outcome)) %>% 
  select(-alc_consumption)

head(alc)

train_alc = alc %>% sample_frac(.7)
test_alc = anti_join(alc, train_alc, by = 'x1') %>% 
  select(-x1)

train_alc = train_alc %>% 
  select(-x1)
```

### 1. Create Models

#### Model 1: Use Caret to choose alpha and lambda

```{r, model1}
# Create model 1
model1 = train(
    alc_outcome ~., 
    data = train_alc,
    method = "glmnet",
    family = "binomial",
    trControl = trainControl("cv", number = 10)
  )

# Test performance
results1 = predict(model1, 
                   test_alc, 
                   type = 'prob')

results_prob1 = ifelse(results1 > 0.5,1,0)

outcome1 = (as.numeric(test_alc$alc_outcome) - 1)

testProbs1 =  data.frame(obs = test_alc$alc_outcome,
                        pred.logit = results_prob1)

missclass1 = mean(
  results_prob1 != outcome1, 
  na.rm = T)

accuracy1 = print(1 - missclass1)

```

#### Model 2: Logistic Regression

```{r, model2}
# Create model2
model2 = glm(
    alc_outcome ~., 
    family = binomial(link = 'logit'),
    data = train_alc
  )

# Test performance
results2 = predict(model2, 
                   test_alc, 
                   type = 'response')

results_prob2 = ifelse(results2 > 0.5,1,0)

outcome2 = (as.numeric(test_alc$alc_outcome) - 1)

testProbs2 = data.frame(obs = test_alc$alc_outcome,
                        pred.logit = results_prob2)

missclass2 = mean(
  results_prob2 != outcome2, 
  na.rm = T)

accuracy2 = print(1 - missclass2)

```

#### Model 3: LASSO using CARET package

```{r, model3}
# Create model 3
lambda = 10^seq(-3,3, length = 100)

model3 = train(
    alc_outcome ~., 
    data = train_alc,
    method = "glmnet",
    family = "binomial",
    trControl = trainControl("cv", number = 10), 
    tuneGrid = expand.grid(alpha = 1, lambda = lambda))

# Test performance
results3 = predict(model3, 
                   test_alc, 
                   type = 'prob')

results_prob3 = ifelse(results3 > 0.5,1,0)

outcome3 = (as.numeric(test_alc$alc_outcome) - 1)

testProbs3 = data.frame(obs = test_alc$alc_outcome,
                        pred.logit = results_prob3)

missclass3 = mean(
  results_prob3 != outcome3, 
  na.rm = T)

accuracy3 = print(1 - missclass3)

```

### 2. Compare Model Performace 

Accuracy of each model: 

```{r, performance}
performance = 
  tibble(
    "Model 1" = c(round(accuracy1, digits = 3)), 
    "Model 2" = c(round(accuracy2, digits = 3)), 
    "Model 3" = c(round(accuracy3, digits = 3))
    ) %>% knitr::kable()

performance
```

Using the above output, I would choose Model 2 which used standard logistic regression. Not only is this computationally less intensive, but it has the highest prediction accuracy. This model also only has 7 parameters, so feature selection is not a high priority. 


### 4. Question
a) Directly address: We were able to identify a model that accurately (77%) explained alcohol use in the past month using 7 personality features. We can answer: are personality traits associated with alcohol use in the past month among the study sample? 

b) Indirectly address: Future researchers could identify more personality characteristics that are associated with alcohol use. With this information, they could create a personality index that accurately predicts alcohol use. This could be used to identify individuals that may have harmful alcohol behaviors. 

