---
title: "Assignment5"
author: "Holly Finertie - HF2379"
date: 'Due: 2/25/2020'
output:
  word_document: default
  html_document: default
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(caret)
library(glmnet)
library(modelr)
library(mgcv)

set.seed(100)
```

Goal: You want to predict current alcohol consumption but it is expensive and time-consuming to administer all of the behavioral testing that produces the personality scores. You will conduct a reproducible analysis to build and test classification models using regularized logistic regression and traditional logistic regression.

### Data Import: Cleaning and Training/Testing Data Set

I imported the data, cleaned the variable names, and converted our outcome of interest to a factor variable named 'alc_outcome'. Then I created training and testing data sets with a 70/30 split. 

```{r, import}
alc = read_csv("./data/alcohol_use.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    alc_outcome = case_when(
      alc_consumption == "CurrentUse" ~ 1, 
      alc_consumption == "NotCurrentUse" ~ 0), 
    alc_outcome = as.factor(alc_outcome)) %>% 
  select(-alc_consumption)

head(alc)

train_alc = alc %>% sample_frac(.7)
test_alc = anti_join(alc, train_alc, by = 'x1')
```

### 1. Create and Compare Models

#### Model 1: Use Caret package to choose alpha and lambda

```{r}
# Apply to Model1
model1 = train(
    alc_outcome ~., 
    data = train_alc,
    method = "glmnet",
    family = "binomial",
    trControl = trainControl("cv", number = 10)
  )

# Test performance
results1 = predict(model1, 
                   test_alc, 
                   type = 'prob')

results_prob1 = ifelse(results1 > 0.5,1,0)

outcome1 = (as.numeric(test_alc$alc_outcome) - 1)

testProbs1 =  data.frame(obs = test_alc$alc_outcome,
                        pred.logit = results_prob1)

missclass1 = mean(
  results_prob1 != outcome1, 
  na.rm = T)

print(paste('Accuracy Model 1',1 - missclass1))

calPlotData1 = calibration(
  obs ~ pred.logit.1, 
  data = testProbs1, 
  cuts = 5)

xyplot(calPlotData1, 
       auto.key = list(columns = 2))
```

#### Model 2: Logistic Regression

```{r}
# Apply to Model1
model2 = glm(
    alc_outcome ~., 
    family = binomial(link = 'logit'),
    data = train_alc
  )

# Test performance
results2 = predict(model2, 
                   test_alc, 
                   type = 'response')

results_prob2 = ifelse(results2 > 0.5,1,0)

outcome2 = (as.numeric(test_alc$alc_outcome) - 1)

testProbs2 = data.frame(obs = test_alc$alc_outcome,
                        pred.logit = results_prob2)

missclass2 = mean(
  results_prob2 != outcome2, 
  na.rm = T)

print(paste('Accuracy Model 2',1 - missclass2))

calPlotData2 = calibration(
  obs ~ pred.logit, 
  data = testProbs2, 
  cuts = 5)

xyplot(calPlotData2, 
       auto.key = list(columns = 2))
```

#### Model 3: LASSO using CARET package

```{r}
# Apply to Model3
lambda = 10^seq(-3,3, length = 100)

model3 = train(
    alc_outcome ~., 
    data = train_alc,
    method = "glmnet",
    family = "binomial",
    trControl = trainControl("cv", number = 10), 
    tuneGrid = expand.grid(alpha = 1, lambda = lambda))

# Test performance
results3 = predict(model3, 
                   test_alc, 
                   type = 'prob')

results_prob3 = ifelse(results3 > 0.5,1,0)

outcome3 = (as.numeric(test_alc$alc_outcome) - 1)

testProbs3 = data.frame(obs = test_alc$alc_outcome,
                        pred.logit = results_prob3)

missclass3 = mean(
  results_prob3 != outcome3, 
  na.rm = T)

print(paste('Accuracy Model 3',1 - missclass3))

calPlotData3 = calibration(
  obs ~ pred.logit.1, 
  data = testProbs3, 
  cuts = 5)

xyplot(calPlotData3, 
       auto.key = list(columns = 2))
```

### 2. Compare Performace of Each Model

Accuracy of each model: 

```{r}
performance = 
  tibble(
    "Accuracy Model 1" = c(1 - missclass1), 
    "Accuracy Model 2" = c(1 - missclass2), 
    "Accuracy Model 3" = c(1 - missclass3)
   ) %>% knitr::kable()

performance
```

Using the above output, I would choose Model 2 which used standard logistic regression to predict. 

